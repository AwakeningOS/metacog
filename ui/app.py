"""
Gradio UI for LLM Awareness Engine

3 tabs:
- Chat: Message input/output + feedback + insight display
- Dashboard: Memory stats, insight history, dreaming controls
- Settings: LM Studio connection, thresholds
"""

import logging
import sys
from pathlib import Path

import gradio as gr


def get_project_root() -> Path:
    """Get project root (works for both dev and frozen exe)"""
    if getattr(sys, 'frozen', False):
        # Running as compiled exe
        return Path(sys.executable).parent
    else:
        # Running as script
        return Path(__file__).parent.parent


# Add project root to path
project_root = get_project_root()
sys.path.insert(0, str(project_root))

from config.default_config import (
    load_config, save_config, load_presets, save_preset, delete_preset,
    SYSTEM_PROMPT, DREAM_PROMPT
)
from engine.core import AwarenessEngine

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(name)s] %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)

# ========== Global State ==========

config = load_config()
data_dir = project_root / "data"
engine = AwarenessEngine(config=config, data_dir=data_dir)

# ========== Custom CSS ==========

CUSTOM_CSS = """
.insight-card {
    background: #1a1a1a;
    border: 1px solid #333;
    border-radius: 8px;
    padding: 12px;
    margin: 8px 0;
    font-size: 0.9em;
}
.feedback-box textarea {
    border: 2px solid #2d5aa0 !important;
    border-radius: 8px;
}
.dream-button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
}
/* ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã« */
.gr-checkbox-group label {
    background: #1a1a1a !important;
    color: #ffffff !important;
    border: 1px solid #333 !important;
}
.gr-checkbox-group label:hover {
    background: #2a2a2a !important;
}
"""


# ========== Chat Handlers ==========

def send_message(message: str, history: list):
    """Process user message and return response"""
    if not message.strip():
        return history, "", ""

    # Send to engine
    response, metadata = engine.send_message(message)

    # Update history
    history = history or []
    history.append({"role": "user", "content": message})
    history.append({"role": "assistant", "content": response})

    # Format thoughts for display
    thoughts = metadata.get("thoughts", [])
    saves = metadata.get("saves", [])

    display_parts = []

    # æ€è€ƒéç¨‹ã‚’è¡¨ç¤º
    if thoughts:
        display_parts.append("### ğŸ§  æ€è€ƒéç¨‹")
        for t in thoughts:
            num = t.get("number", "?")
            total = t.get("total", "?")
            thought = t.get("thought", "")
            if thought:
                # é•·ã„æ€è€ƒã¯çœç•¥
                short = thought[:200] + "..." if len(thought) > 200 else thought
                display_parts.append(f"\n**[{num}/{total}]** {short}")

    # ä¿å­˜ã—ãŸè¨˜æ†¶
    if saves:
        display_parts.append("\n### ğŸ’¾ ä¿å­˜ã—ãŸè¨˜æ†¶")
        for s in saves:
            display_parts.append(f"- {s}")

    insight_display = "\n".join(display_parts)

    return history, "", insight_display


def submit_feedback(feedback: str):
    """Submit user feedback"""
    if not feedback.strip():
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", ""

    success = engine.submit_feedback(feedback)
    if success:
        return "âœ… ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆæ¬¡ã®å¤¢è¦‹ã§å‡¦ç†ã•ã‚Œã¾ã™ï¼‰", ""
    else:
        return "âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ", feedback


def clear_chat():
    """Clear conversation"""
    engine.clear_conversation()
    return [], "", ""


def format_chat_for_copy(history: list) -> str:
    """Format chat history for clipboard copy"""
    if not history:
        return ""

    lines = []
    for msg in history:
        role = msg.get("role", "")
        content = msg.get("content", "")
        if role == "user":
            lines.append(f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€‘\n{content}")
        elif role == "assistant":
            lines.append(f"ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€‘\n{content}")

    return "\n\n---\n\n".join(lines)


# ========== Dashboard Handlers ==========

def get_dashboard_data():
    """Get dashboard statistics"""
    stats = engine.get_stats()
    threshold = engine.check_dream_threshold()

    stats_text = f"""### ğŸ“Š è“„ç©ãƒ‡ãƒ¼ã‚¿

| é …ç›® | ä»¶æ•° |
|------|------|
| ğŸ“¦ è¨˜æ†¶ï¼ˆChromaDBï¼‰ | {stats['total_chromadb']} |
| ğŸ’¬ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ | {stats['feedback_count']} |

### ğŸŒ™ å¤¢è¦‹

| é …ç›® | å€¤ |
|------|-----|
| å®Ÿè¡Œå›æ•° | {stats['dream_cycles']}å› |
| æœ€çµ‚å®Ÿè¡Œ | {stats.get('last_dream', 'æœªå®Ÿè¡Œ')} |
| æ¨å¥¨ | {'âœ¨ ã¯ã„' if threshold['should_dream'] else 'ã„ã„ãˆ'} |
"""

    return stats_text


def get_dream_data():
    """Get all memories and feedback for dream tab selection"""
    export = engine.memory.export_for_dreaming()
    memories = export.get("memories", [])
    feedbacks = export.get("feedback", [])

    # è¨˜æ†¶ä¸€è¦§ã‚’ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ç”¨ã«æ•´å½¢
    # content ã¯æ—¢ã« [ã‚«ãƒ†ã‚´ãƒª] å†…å®¹ å½¢å¼ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾ä½¿ç”¨
    memory_choices = []
    for mem in memories:
        content = mem.get("content", "")[:120]  # è¡¨ç¤ºç”¨ã«120æ–‡å­—ã¾ã§
        mem_id = mem.get("id", "")
        memory_choices.append((content, mem_id))

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¸€è¦§
    feedback_choices = []
    for i, fb in enumerate(feedbacks):
        text = fb.get("feedback", "")[:100]
        feedback_choices.append((text, str(i)))

    return memory_choices, feedback_choices


def trigger_dream_with_selection(selected_memory_ids: list, selected_feedback_ids: list):
    """Trigger dreaming cycle with selected memories and feedback"""
    # TODO: é¸æŠçš„ãªå¤¢è¦‹ã‚’å®Ÿè£…ï¼ˆç¾åœ¨ã¯å…¨è¨˜æ†¶ã§å®Ÿè¡Œï¼‰
    result = engine.trigger_dream()

    if result["status"] == "completed":
        generated_memories = "\n".join([f"- {ins}" for ins in result.get("insights", [])])
        return f"""### ğŸŒ™ å¤¢è¦‹å®Œäº†ï¼

**ã€å¤¢è¦‹å…¥åŠ›ã€‘**
- ä½¿ç”¨ã—ãŸè¨˜æ†¶: {result.get('memories_processed', 0)}ä»¶ â†’ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»å‹•
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {result.get('feedbacks_used', 0)}ä»¶

**ã€ç”Ÿæˆã•ã‚ŒãŸè¨˜æ†¶ã€‘**ï¼ˆChromaDBã«ä¿å­˜æ¸ˆã¿ï¼‰
{generated_memories}

å‡¦ç†æ™‚é–“: {result.get('duration_seconds', 0):.1f}ç§’
"""
    elif result["status"] == "skipped":
        return f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {result.get('reason', '')}"
    else:
        return f"âŒ å¤±æ•—: {result.get('reason', '')}"


def trigger_dream():
    """Trigger dreaming cycle (legacy - all memories)"""
    return trigger_dream_with_selection([], [])


def reset_memory():
    """Reset all memories"""
    result = engine.reset_memory()
    return f"""### ğŸ—‘ï¸ è¨˜æ†¶ãƒªã‚»ãƒƒãƒˆå®Œäº†

- ChromaDB: {result.get('chromadb_deleted', 0)}ä»¶ å‰Šé™¤
- ã‚¤ãƒ³ã‚µã‚¤ãƒˆ: {result.get('insights_deleted', 0)}ä»¶ å‰Šé™¤
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {result.get('feedback_deleted', 0)}ä»¶ å‰Šé™¤

è¨˜æ†¶ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚"""


def reset_everything():
    """Reset ALL data including archives and logs"""
    result = engine.reset_everything()
    return f"""### âš ï¸ å®Œå…¨ãƒªã‚»ãƒƒãƒˆå®Œäº†

**è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿:**
- ChromaDB: {result.get('chromadb_deleted', 0)}ä»¶ å‰Šé™¤
- ã‚¤ãƒ³ã‚µã‚¤ãƒˆ: {result.get('insights_deleted', 0)}ä»¶ å‰Šé™¤
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {result.get('feedback_deleted', 0)}ä»¶ å‰Šé™¤

**ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ»ãƒ­ã‚°:**
- è¨˜æ†¶ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {result.get('memory_archive_deleted', 0)}ä»¶ å‰Šé™¤
- å¤¢è¦‹ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {result.get('dream_archives_deleted', 0)}ä»¶ å‰Šé™¤
- ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {result.get('insights_archived_deleted', 0)}ä»¶ å‰Šé™¤
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {result.get('feedback_archived_deleted', 0)}ä»¶ å‰Šé™¤

å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚"""


# ========== Settings Handlers ==========

def test_connection():
    """Test LM Studio connection"""
    result = engine.check_connection()
    if result["status"] == "connected":
        models = ", ".join(result.get("loaded_model_names", []))
        return f"âœ… æ¥ç¶šæˆåŠŸ\nãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {models or 'ãªã— (JITã§è‡ªå‹•ãƒ­ãƒ¼ãƒ‰)'}"
    elif result["status"] == "disconnected":
        return "âŒ LM Studioã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚èµ·å‹•ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ"
    else:
        return f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', '')}"


def save_settings(host, port, api_token, context_length, dream_threshold, search_threshold, auto_save_exchange, selected_model):
    """Save user settings including model selection"""
    logger.info(f"save_settings called with selected_model={selected_model}, context_length={context_length}")

    updates = {
        "lm_studio": {
            "host": host,
            "port": int(port),
            "api_token": api_token,
            "context_length": int(context_length),
        },
        "dreaming": {
            "memory_threshold": int(dream_threshold),
        },
        "search_relevance_threshold": float(search_threshold),
        "auto_save_exchange": bool(auto_save_exchange),
        "selected_model": selected_model,
    }

    if save_config(updates):
        # Reinitialize engine with new config
        global engine, config
        config = load_config()
        logger.info(f"After reload, config selected_model={config.get('selected_model')}")
        engine = AwarenessEngine(config=config, data_dir=data_dir)
        logger.info(f"Engine lm_client.selected_model={engine.lm_client.selected_model}")
        return f"âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆãƒ¢ãƒ‡ãƒ«: {selected_model or 'è‡ªå‹•æ¤œå‡º'}ï¼‰"
    else:
        return "âŒ è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"


# ========== Prompt & Model Handlers ==========

def get_model_choices():
    """Get available models from LM Studio"""
    try:
        models = engine.get_available_models()
        # Get saved selection from config file (reload to get latest)
        current_config = load_config()
        saved_model = current_config.get("selected_model", "")
        logger.info(f"get_model_choices: models={models}, saved_model={saved_model}")
        if models:
            # If saved model exists in list, use it; otherwise use first model
            if saved_model and saved_model in models:
                return models, saved_model
            return models, models[0]
        return ["(ãƒ¢ãƒ‡ãƒ«ãªã—)"], "(ãƒ¢ãƒ‡ãƒ«ãªã—)"
    except Exception as e:
        logger.error(f"get_model_choices error: {e}")
        return ["(æ¥ç¶šã‚¨ãƒ©ãƒ¼)"], "(æ¥ç¶šã‚¨ãƒ©ãƒ¼)"


def refresh_models():
    """Refresh model list from LM Studio"""
    try:
        models = engine.get_available_models()
        logger.info(f"refresh_models: found {len(models)} models: {models}")
        if models:
            # Don't auto-select - just update the list, keep current dropdown value
            return gr.update(choices=models)
        return gr.update(choices=["(ãƒ¢ãƒ‡ãƒ«ãªã—)"])
    except Exception as e:
        logger.error(f"refresh_models error: {e}")
        return gr.update(choices=["(æ¥ç¶šã‚¨ãƒ©ãƒ¼)"])


def update_context_slider_max(selected_model: str):
    """Update context length slider maximum based on selected model"""
    try:
        if not selected_model or selected_model in ["(ãƒ¢ãƒ‡ãƒ«ãªã—)", "(æ¥ç¶šã‚¨ãƒ©ãƒ¼)"]:
            return gr.update()

        model_info = engine.get_model_info(selected_model)
        max_ctx = model_info.get("max_context_length", 32000)
        logger.info(f"Model {selected_model}: max_context_length={max_ctx}")

        # Get current value from config
        current_value = config.get("lm_studio", {}).get("context_length", 32000)
        # Clamp current value to new maximum
        new_value = min(current_value, max_ctx)

        return gr.update(maximum=max_ctx, value=new_value)
    except Exception as e:
        logger.error(f"update_context_slider_max error: {e}")
        return gr.update()


def save_prompts(system_prompt, dream_prompt, selected_model):
    """Save system prompts and model selection"""
    updates = {
        "system_prompt": system_prompt,
        "dream_prompt": dream_prompt,
        "selected_model": selected_model,
    }

    if save_config(updates):
        global engine, config
        config = load_config()
        engine = AwarenessEngine(config=config, data_dir=data_dir)
        return "âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    else:
        return "âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"


def get_preset_choices():
    """Get preset list for dropdown"""
    presets = load_presets()
    return [(v["name"], k) for k, v in presets.items()]


def load_preset_prompts(preset_id):
    """Load prompts from a preset"""
    presets = load_presets()
    if preset_id in presets:
        preset = presets[preset_id]
        return preset["system_prompt"], preset["dream_prompt"], f"âœ… ã€Œ{preset['name']}ã€ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ"
    return "", "", "âŒ ãƒ—ãƒªã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"


def save_new_preset(preset_name, system_prompt, dream_prompt):
    """Save current prompts as a new preset"""
    if not preset_name.strip():
        return gr.update(), "âŒ ãƒ—ãƒªã‚»ãƒƒãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"

    # Generate ID from name
    import re
    preset_id = re.sub(r'[^\w]', '_', preset_name.lower())

    if save_preset(preset_id, preset_name, system_prompt, dream_prompt):
        choices = get_preset_choices()
        return gr.update(choices=choices, value=preset_id), f"âœ… ã€Œ{preset_name}ã€ã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    else:
        return gr.update(), "âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"


def delete_current_preset(preset_id):
    """Delete the selected preset"""
    if preset_id == "default":
        return gr.update(), "âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒªã‚»ãƒƒãƒˆã¯å‰Šé™¤ã§ãã¾ã›ã‚“"

    presets = load_presets()
    preset_name = presets.get(preset_id, {}).get("name", preset_id)

    if delete_preset(preset_id):
        choices = get_preset_choices()
        return gr.update(choices=choices, value="default"), f"âœ… ã€Œ{preset_name}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
    else:
        return gr.update(), "âŒ å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ"


def reset_to_default():
    """Reset prompts to default values"""
    return SYSTEM_PROMPT, DREAM_PROMPT, "âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã—ã¾ã—ãŸ"


# ========== Build UI ==========

def create_app():
    """Create Gradio application"""
    with gr.Blocks(
        title="LLM Awareness Engine",
    ) as app:

        with gr.Row():
            with gr.Column(scale=9):
                gr.Markdown("# ğŸ§  LLM Awareness Engine")
            with gr.Column(scale=1):
                shutdown_btn = gr.Button("ğŸ›‘ çµ‚äº†", variant="stop", size="sm")

        gr.Markdown("*è¨€èªãŒè¨€èªè‡ªèº«ã‚’å‡¦ç†ã™ã‚‹*")

        with gr.Tabs():
            # ========== Tab 1: Chat ==========
            with gr.TabItem("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ"):
                with gr.Row():
                    with gr.Column(scale=3):
                        chatbot = gr.Chatbot(
                            height=500,
                            label="å¯¾è©±",
                            buttons=["copy"],
                        )
                        with gr.Row():
                            msg_input = gr.Textbox(
                                placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...",
                                label="å…¥åŠ›",
                                scale=5,
                                lines=1,
                                max_lines=5,
                            )
                            send_btn = gr.Button("é€ä¿¡", variant="primary", scale=1)

                        with gr.Row():
                            clear_btn = gr.Button("ğŸ—‘ï¸ ä¼šè©±ã‚¯ãƒªã‚¢")
                            copy_chat_btn = gr.Button("ğŸ“‹ å…¨ä½“ã‚³ãƒ”ãƒ¼")

                    with gr.Column(scale=2):
                        insight_display = gr.Markdown(
                            value="",
                            label="è¦³å¯Ÿãƒ»ä¿å­˜è¨˜æ†¶",
                        )

                        gr.Markdown("### ğŸ“ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
                        feedback_input = gr.Textbox(
                            placeholder="å¿œç­”ã¸ã®æ„Ÿæƒ³ã‚„æ”¹å–„ç‚¹ã‚’å…¥åŠ›...",
                            label="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯",
                            lines=2,
                        )
                        feedback_btn = gr.Button("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡")
                        feedback_status = gr.Textbox(
                            label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
                            interactive=False,
                        )

                # Chat events (time_limit=600 for long LLM responses)
                send_btn.click(
                    send_message,
                    inputs=[msg_input, chatbot],
                    outputs=[chatbot, msg_input, insight_display],
                    time_limit=600,
                )
                msg_input.submit(
                    send_message,
                    inputs=[msg_input, chatbot],
                    outputs=[chatbot, msg_input, insight_display],
                    time_limit=600,
                )
                clear_btn.click(
                    clear_chat,
                    outputs=[chatbot, msg_input, insight_display],
                )

                # Hidden textbox to hold formatted chat for copying
                copy_text = gr.Textbox(visible=False)

                copy_chat_btn.click(
                    format_chat_for_copy,
                    inputs=[chatbot],
                    outputs=[copy_text],
                ).then(
                    None,
                    inputs=[copy_text],
                    js="(text) => { navigator.clipboard.writeText(text); }",
                )

                feedback_btn.click(
                    submit_feedback,
                    inputs=[feedback_input],
                    outputs=[feedback_status, feedback_input],
                )

            # ========== Tab 2: Dashboard (çµ±è¨ˆã®ã¿) ==========
            with gr.TabItem("ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"):
                with gr.Row():
                    refresh_btn = gr.Button("ğŸ”„ æ›´æ–°")

                stats_display = gr.Markdown(label="çµ±è¨ˆ")

                # Dashboard events
                refresh_btn.click(
                    get_dashboard_data,
                    outputs=[stats_display],
                )

            # ========== Tab 3: Dream (è¨˜æ†¶é¸æŠ + å¤¢è¦‹å®Ÿè¡Œ) ==========
            with gr.TabItem("ğŸŒ™ å¤¢è¦‹"):
                with gr.Row():
                    refresh_dream_btn = gr.Button("ğŸ”„ ä¸€è¦§ã‚’æ›´æ–°")
                    dream_btn = gr.Button(
                        "ğŸŒ™ å¤¢è¦‹ã‚’å®Ÿè¡Œ",
                        variant="primary",
                        elem_classes=["dream-button"],
                    )
                    delete_selected_btn = gr.Button(
                        "ğŸ—‘ï¸ é¸æŠã—ãŸè¨˜æ†¶ã‚’å‰Šé™¤",
                        variant="stop",
                    )

                dream_result = gr.Markdown(label="çµæœ")

                gr.Markdown("---")
                gr.Markdown("### ğŸ“¦ ChromaDBè¨˜æ†¶ä¸€è¦§")
                with gr.Row():
                    select_all_btn = gr.Button("â˜‘ï¸ å…¨é¸æŠ", size="sm")
                    deselect_all_btn = gr.Button("â˜ å…¨è§£é™¤", size="sm")

                memory_checkboxes = gr.CheckboxGroup(
                    choices=[],
                    label="è¨˜æ†¶ä¸€è¦§",
                    value=[],
                )

                gr.Markdown("---")
                gr.Markdown("### ğŸ’¬ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¸€è¦§")

                feedback_checkboxes = gr.CheckboxGroup(
                    choices=[],
                    label="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¸€è¦§",
                    value=[],
                )

                # ========== ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ==========
                gr.Markdown("---")
                gr.Markdown("### ğŸ“ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆå¤¢è¦‹ã§ä½¿ç”¨æ¸ˆã¿ã®è¨˜æ†¶ï¼‰")
                gr.Markdown("*å¤¢è¦‹å‡¦ç†ã§çµ±åˆã•ã‚ŒãŸè¨˜æ†¶ãŒã“ã“ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å¾©å…ƒã§ãã¾ã™ã€‚*")

                with gr.Row():
                    refresh_archive_btn = gr.Button("ğŸ”„ æ›´æ–°", size="sm")
                    select_all_archive_btn = gr.Button("â˜‘ï¸ å…¨é¸æŠ", size="sm")
                    deselect_all_archive_btn = gr.Button("â˜ å…¨è§£é™¤", size="sm")
                    restore_btn = gr.Button("â™»ï¸ é¸æŠã‚’å¾©å…ƒ", variant="primary", size="sm")
                    delete_archive_btn = gr.Button("ğŸ—‘ï¸ å®Œå…¨ã«å‰Šé™¤", variant="stop", size="sm")

                archive_status = gr.Markdown("")

                archive_checkboxes = gr.CheckboxGroup(
                    choices=[],
                    label="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§",
                    value=[],
                )

                # Dream tab events
                def refresh_dream_lists():
                    memory_choices, feedback_choices = get_dream_data()
                    # å…¨é¸æŠçŠ¶æ…‹ã§è¿”ã™
                    memory_values = [m[1] for m in memory_choices]
                    feedback_values = [f[1] for f in feedback_choices]
                    return (
                        gr.update(choices=memory_choices, value=memory_values),
                        gr.update(choices=feedback_choices, value=feedback_values),
                    )

                def show_processing():
                    return "### â³ å¤¢è¦‹å‡¦ç†ä¸­...\n\n*MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦è¨˜æ†¶ã‚’çµ±åˆã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...*"

                def delete_selected_memories(selected_ids):
                    if not selected_ids:
                        return "âš ï¸ å‰Šé™¤ã™ã‚‹è¨˜æ†¶ã‚’é¸æŠã—ã¦ãã ã•ã„"
                    result = engine.memory.batch_delete(selected_ids)
                    return f"âœ… {result['deleted_count']}ä»¶ã®è¨˜æ†¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"

                # å…¨é¸æŠ/å…¨è§£é™¤é–¢æ•°
                def select_all_memories():
                    memory_choices, _ = get_dream_data()
                    all_ids = [m[1] for m in memory_choices]
                    return gr.update(value=all_ids)

                def deselect_all_memories():
                    return gr.update(value=[])

                # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç”¨é–¢æ•°
                def get_archive_data():
                    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‹ã‚‰è¨˜æ†¶ä¸€è¦§ã‚’å–å¾—"""
                    archived = engine.memory.get_archived_memories()
                    choices = []
                    for i, entry in enumerate(archived):
                        content = entry.get("content", "")[:80]
                        archived_at = entry.get("archived_at", "")[:10]
                        choices.append((f"[{archived_at}] {content}", str(i)))
                    return gr.update(choices=choices, value=[])

                def select_all_archive():
                    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å…¨é¸æŠ"""
                    archived = engine.memory.get_archived_memories()
                    all_ids = [str(i) for i in range(len(archived))]
                    return gr.update(value=all_ids)

                def deselect_all_archive():
                    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å…¨è§£é™¤"""
                    return gr.update(value=[])

                def restore_selected_archive(selected_indices):
                    """é¸æŠã—ãŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å¾©å…ƒ"""
                    if not selected_indices:
                        return "âš ï¸ å¾©å…ƒã™ã‚‹è¨˜æ†¶ã‚’é¸æŠã—ã¦ãã ã•ã„"
                    indices = [int(i) for i in selected_indices]
                    result = engine.memory.restore_memories(indices)
                    return f"âœ… {result['restored_count']}ä»¶ã®è¨˜æ†¶ã‚’å¾©å…ƒã—ã¾ã—ãŸ"

                def delete_selected_archive(selected_indices):
                    """é¸æŠã—ãŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å®Œå…¨å‰Šé™¤"""
                    if not selected_indices:
                        return "âš ï¸ å‰Šé™¤ã™ã‚‹è¨˜æ†¶ã‚’é¸æŠã—ã¦ãã ã•ã„"
                    indices = [int(i) for i in selected_indices]
                    result = engine.memory.delete_archived_memories(indices)
                    return f"âœ… {result['deleted_count']}ä»¶ã®è¨˜æ†¶ã‚’å®Œå…¨ã«å‰Šé™¤ã—ã¾ã—ãŸ"

                refresh_dream_btn.click(
                    refresh_dream_lists,
                    outputs=[memory_checkboxes, feedback_checkboxes],
                )
                # å…¨é¸æŠ/å…¨è§£é™¤ãƒœã‚¿ãƒ³
                select_all_btn.click(
                    select_all_memories,
                    outputs=[memory_checkboxes],
                )
                deselect_all_btn.click(
                    deselect_all_memories,
                    outputs=[memory_checkboxes],
                )
                # å¤¢è¦‹ãƒœã‚¿ãƒ³: ã¾ãšã€Œå‡¦ç†ä¸­ã€ã‚’è¡¨ç¤ºã—ã¦ã‹ã‚‰å®Ÿè¡Œ
                dream_btn.click(
                    show_processing,
                    outputs=[dream_result],
                ).then(
                    trigger_dream_with_selection,
                    inputs=[memory_checkboxes, feedback_checkboxes],
                    outputs=[dream_result],
                ).then(
                    refresh_dream_lists,
                    outputs=[memory_checkboxes, feedback_checkboxes],
                ).then(
                    get_archive_data,
                    outputs=[archive_checkboxes],
                )
                # å‰Šé™¤ãƒœã‚¿ãƒ³
                delete_selected_btn.click(
                    delete_selected_memories,
                    inputs=[memory_checkboxes],
                    outputs=[dream_result],
                ).then(
                    refresh_dream_lists,
                    outputs=[memory_checkboxes, feedback_checkboxes],
                )

                # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ“ä½œ
                refresh_archive_btn.click(
                    get_archive_data,
                    outputs=[archive_checkboxes],
                )
                select_all_archive_btn.click(
                    select_all_archive,
                    outputs=[archive_checkboxes],
                )
                deselect_all_archive_btn.click(
                    deselect_all_archive,
                    outputs=[archive_checkboxes],
                )
                restore_btn.click(
                    restore_selected_archive,
                    inputs=[archive_checkboxes],
                    outputs=[archive_status],
                ).then(
                    get_archive_data,
                    outputs=[archive_checkboxes],
                ).then(
                    refresh_dream_lists,
                    outputs=[memory_checkboxes, feedback_checkboxes],
                )
                delete_archive_btn.click(
                    delete_selected_archive,
                    inputs=[archive_checkboxes],
                    outputs=[archive_status],
                ).then(
                    get_archive_data,
                    outputs=[archive_checkboxes],
                )

                # Auto-refresh on tab load
                app.load(
                    get_dashboard_data,
                    outputs=[stats_display],
                )

            # ========== Tab 4: Settings ==========
            with gr.TabItem("âš™ï¸ è¨­å®š"):

                with gr.Tabs():
                    # ===== Sub-tab: Prompts =====
                    with gr.TabItem("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"):
                        gr.Markdown("### ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š")

                        # Preset management
                        with gr.Row():
                            preset_dropdown = gr.Dropdown(
                                choices=get_preset_choices(),
                                value="default",
                                label="ãƒ—ãƒªã‚»ãƒƒãƒˆ",
                                scale=3,
                            )
                            load_preset_btn = gr.Button("ğŸ“‚ èª­è¾¼", scale=1)
                            delete_preset_btn = gr.Button("ğŸ—‘ï¸ å‰Šé™¤", scale=1)

                        with gr.Row():
                            new_preset_name = gr.Textbox(
                                placeholder="æ–°ã—ã„ãƒ—ãƒªã‚»ãƒƒãƒˆå...",
                                label="ãƒ—ãƒªã‚»ãƒƒãƒˆå",
                                scale=3,
                            )
                            save_preset_btn = gr.Button("ğŸ’¾ æ–°è¦ä¿å­˜", scale=1)

                        preset_status = gr.Textbox(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False)

                        gr.Markdown("---")

                        # Chat system prompt
                        gr.Markdown("#### ğŸ’¬ ãƒãƒ£ãƒƒãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
                        system_prompt_input = gr.Textbox(
                            value=config.get("system_prompt", SYSTEM_PROMPT),
                            label="",
                            lines=12,
                            max_lines=20,
                        )

                        gr.Markdown("#### ğŸŒ™ å¤¢è¦‹ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
                        gr.Markdown("*`{user_feedback}`, `{saved_memories}` ãŒè‡ªå‹•ç½®æ›ã•ã‚Œã¾ã™*")
                        dream_prompt_input = gr.Textbox(
                            value=config.get("dream_prompt", DREAM_PROMPT),
                            label="",
                            lines=12,
                            max_lines=20,
                        )

                        gr.Markdown("---")

                        with gr.Row():
                            reset_prompts_btn = gr.Button("ğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™")
                            save_prompts_btn = gr.Button("ğŸ’¾ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜", variant="primary")

                        prompts_status = gr.Textbox(label="ä¿å­˜çŠ¶æ…‹", interactive=False)

                        # Prompt events
                        load_preset_btn.click(
                            load_preset_prompts,
                            inputs=[preset_dropdown],
                            outputs=[system_prompt_input, dream_prompt_input, preset_status],
                        )
                        save_preset_btn.click(
                            save_new_preset,
                            inputs=[new_preset_name, system_prompt_input, dream_prompt_input],
                            outputs=[preset_dropdown, preset_status],
                        )
                        delete_preset_btn.click(
                            delete_current_preset,
                            inputs=[preset_dropdown],
                            outputs=[preset_dropdown, preset_status],
                        )
                        reset_prompts_btn.click(
                            reset_to_default,
                            outputs=[system_prompt_input, dream_prompt_input, prompts_status],
                        )

                    # ===== Sub-tab: Model & Connection =====
                    with gr.TabItem("ğŸ”Œ æ¥ç¶šãƒ»ãƒ¢ãƒ‡ãƒ«"):
                        gr.Markdown("### LM Studio æ¥ç¶šè¨­å®š")

                        with gr.Row():
                            host_input = gr.Textbox(
                                value=config.get("lm_studio", {}).get("host", "localhost"),
                                label="Host",
                            )
                            port_input = gr.Number(
                                value=config.get("lm_studio", {}).get("port", 1234),
                                label="Port",
                                precision=0,
                            )

                        api_token_input = gr.Textbox(
                            value=config.get("lm_studio", {}).get("api_token", ""),
                            label="API Token",
                            type="password",
                        )

                        conn_btn = gr.Button("æ¥ç¶šãƒ†ã‚¹ãƒˆ")
                        conn_status = gr.Textbox(label="æ¥ç¶šçŠ¶æ…‹", interactive=False)

                        gr.Markdown("---")
                        gr.Markdown("### ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")

                        models, current_model = get_model_choices()
                        with gr.Row():
                            model_dropdown = gr.Dropdown(
                                choices=models,
                                value=config.get("selected_model") or current_model,
                                label="ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
                                scale=4,
                            )
                            refresh_models_btn = gr.Button("ğŸ”„ æ›´æ–°", scale=1)

                        gr.Markdown("*LM Studioã§èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ãŒè¡¨ç¤ºã•ã‚Œã¾ã™*")

                        gr.Markdown("---")
                        gr.Markdown("### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·")

                        # é¸æŠä¸­ãƒ¢ãƒ‡ãƒ«ã®max_context_lengthã‚’å–å¾—
                        initial_model = config.get("selected_model") or current_model
                        initial_max_ctx = 131072  # fallback
                        if initial_model and initial_model not in ["(ãƒ¢ãƒ‡ãƒ«ãªã—)", "(æ¥ç¶šã‚¨ãƒ©ãƒ¼)"]:
                            try:
                                model_info = engine.get_model_info(initial_model)
                                initial_max_ctx = model_info.get("max_context_length", 131072)
                            except Exception:
                                pass

                        context_length_slider = gr.Slider(
                            minimum=4096,
                            maximum=initial_max_ctx,
                            step=1024,
                            value=min(config.get("lm_studio", {}).get("context_length", 32000), initial_max_ctx),
                            label="ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰",
                        )
                        gr.Markdown("*ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ™‚ã«æœ€å¤§å€¤ãŒè‡ªå‹•èª¿æ•´ã•ã‚Œã¾ã™ã€‚é•·ã„ã»ã©VRAMä½¿ç”¨é‡ãŒå¢—åŠ ã—ã¾ã™ã€‚*")

                        gr.Markdown("---")
                        gr.Markdown("### ğŸ” è¨˜æ†¶æ¤œç´¢è¨­å®š")

                        search_threshold_slider = gr.Slider(
                            minimum=0.5,
                            maximum=1.0,
                            step=0.01,
                            value=config.get("search_relevance_threshold", 0.85),
                            label="æ¤œç´¢é–¾å€¤ï¼ˆã“ã®å€¤æœªæº€ã®çµæœã¯é™¤å¤–ï¼‰",
                        )
                        gr.Markdown("*é«˜ã„ã»ã©å³æ ¼ã€‚0.85æ¨å¥¨ã€‚*")

                        gr.Markdown("---")
                        gr.Markdown("### ğŸ’¾ è‡ªå‹•ä¿å­˜è¨­å®š")

                        auto_save_checkbox = gr.Checkbox(
                            value=config.get("auto_save_exchange", True),
                            label="å…¥å‡ºåŠ›ãƒšã‚¢ã‚’è‡ªå‹•ä¿å­˜ï¼ˆcategory: exchangeï¼‰",
                        )

                        gr.Markdown("---")
                        gr.Markdown("### å¤¢è¦‹è¨­å®š")

                        dream_threshold_input = gr.Number(
                            value=config.get("dreaming", {}).get("memory_threshold", 30),
                            label="å¤¢è¦‹ãƒˆãƒªã‚¬ãƒ¼é–¾å€¤ï¼ˆãƒ¡ãƒ¢ãƒªæ•°ï¼‰",
                            precision=0,
                        )

                        save_btn = gr.Button("è¨­å®šã‚’ä¿å­˜", variant="primary")
                        save_status = gr.Textbox(label="ä¿å­˜çŠ¶æ…‹", interactive=False)

                        # Connection & Model events
                        conn_btn.click(
                            test_connection,
                            outputs=[conn_status],
                        )
                        refresh_models_btn.click(
                            refresh_models,
                            outputs=[model_dropdown],
                        )
                        # ãƒ¢ãƒ‡ãƒ«é¸æŠæ™‚ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®æœ€å¤§å€¤ã‚’æ›´æ–°
                        model_dropdown.change(
                            update_context_slider_max,
                            inputs=[model_dropdown],
                            outputs=[context_length_slider],
                        )
                        save_btn.click(
                            save_settings,
                            inputs=[host_input, port_input, api_token_input, context_length_slider, dream_threshold_input, search_threshold_slider, auto_save_checkbox, model_dropdown],
                            outputs=[save_status],
                        )

                        # Save prompts with model (connected to prompts tab)
                        save_prompts_btn.click(
                            save_prompts,
                            inputs=[system_prompt_input, dream_prompt_input, model_dropdown],
                            outputs=[prompts_status],
                        )

                    # ===== Sub-tab: Data Reset =====
                    with gr.TabItem("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"):
                        gr.Markdown("### ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ")

                        gr.Markdown("**é€šå¸¸ãƒªã‚»ãƒƒãƒˆ**: è¨˜æ†¶ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€æ€è€ƒãƒ­ã‚°ã‚’å‰Šé™¤ï¼ˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯ä¿æŒï¼‰")
                        reset_btn = gr.Button(
                            "ğŸ—‘ï¸ è¨˜æ†¶ã‚’æ¶ˆå»",
                            variant="stop",
                        )

                        gr.Markdown("---")

                        gr.Markdown("**å®Œå…¨ãƒªã‚»ãƒƒãƒˆ**: å…¨ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨˜æ†¶ + ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– + ãƒ­ã‚°å…¨ã¦ï¼‰ã‚’å®Œå…¨å‰Šé™¤")
                        reset_all_btn = gr.Button(
                            "âš ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨æ¶ˆå»",
                            variant="stop",
                        )

                        reset_result = gr.Markdown(label="ãƒªã‚»ãƒƒãƒˆçµæœ")

                        reset_btn.click(
                            reset_memory,
                            outputs=[reset_result],
                        )
                        reset_all_btn.click(
                            reset_everything,
                            outputs=[reset_result],
                        )

        # ========== Global: Shutdown Button ==========
        def shutdown_server():
            """Gradioã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ãƒãƒ¼ãƒˆã‚’è§£æ”¾"""
            import os
            os._exit(0)

        shutdown_btn.click(
            shutdown_server,
            inputs=[],
            outputs=[],
        )

    # Enable queue with longer timeout for LLM responses
    app.queue(default_concurrency_limit=1)

    return app


# ========== Entry Point ==========

def main():
    """Launch the application"""
    app = create_app()

    # Try ports 7860-7863
    for port in range(7860, 7864):
        try:
            app.launch(
                server_name="127.0.0.1",
                server_port=port,
                share=False,
                inbrowser=True,
                css=CUSTOM_CSS,
                theme=gr.themes.Soft(),
            )
            break
        except OSError:
            logger.warning(f"Port {port} in use, trying next...")
            continue


if __name__ == "__main__":
    main()

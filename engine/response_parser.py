"""
Response Parser

Splits LLM output into:
1. Response text — returned to the user
2. Observations — extracted from "## 観察" section
3. Voluntary saves — lines starting with [SAVE], saved to ChromaDB

Diff is generated by a separate API call in core.py, not parsed here.
"""

import logging

logger = logging.getLogger(__name__)


class ResponseParser:
    """Parse LLM output into response + observations + voluntary memories"""

    OBSERVATION_HEADER = "## 観察"
    SAVE_MARKER = "[SAVE]"
    SEPARATOR = "---"

    # Instruction copy detection
    INSTRUCTION_KEYWORDS = ['記述せよ', '一行で', '識別し', '観察し観察している', '処理過程を観察']

    def parse(self, raw_output: str) -> dict:
        """
        Parse raw LLM output.

        Returns:
            {
                "response": str,
                "observations": list[str],
                "saves": list[str],
                "raw": str,
            }
        """
        if not raw_output:
            return {
                "response": "",
                "observations": [],
                "saves": [],
                "raw": "",
            }

        response = raw_output
        observations = []
        saves = []

        # Split on "## 観察" header
        header_found = False
        for header in [self.OBSERVATION_HEADER, "##観察"]:
            if header in raw_output:
                header_found = True
                parts = raw_output.split(header, 1)

                # Clean up response: remove trailing "---" separator
                response = parts[0].rstrip()
                if response.endswith(self.SEPARATOR):
                    response = response[:-len(self.SEPARATOR)].rstrip()

                # Parse observation section
                observation_section = parts[1]
                for line in observation_section.strip().split("\n"):
                    line = line.strip()

                    # Remove list markers
                    if line.startswith("- "):
                        line = line[2:].strip()
                    elif line.startswith("* "):
                        line = line[2:].strip()

                    if not line:
                        continue

                    # Check for [SAVE] markers
                    if line.upper().startswith(self.SAVE_MARKER):
                        save_content = line[len(self.SAVE_MARKER):].strip()
                        if save_content:
                            saves.append(save_content)
                            logger.debug(f"Extracted [SAVE]: {save_content[:60]}...")
                    elif len(line) > 5:
                        # Filter instruction copies
                        is_copy = any(kw in line for kw in self.INSTRUCTION_KEYWORDS)
                        if is_copy:
                            logger.warning(f"Filtered instruction copy: {line[:60]}...")
                            continue
                        observations.append(line)
                        break  # 1 observation only

                break

        if header_found:
            logger.info(f"Found '## 観察' header")

        if observations:
            logger.info(f"Parsed: {len(observations)} observations, {len(saves)} saves")
        elif header_found:
            logger.warning("Header found but no observation extracted")

        return {
            "response": response,
            "observations": observations,
            "saves": saves,
            "raw": raw_output,
        }
